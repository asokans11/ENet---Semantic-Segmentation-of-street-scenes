{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcMcMd6eMiw3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as tvt\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shuqTSroMuTU"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, folder_path = '', label_path = '', transform = [tvt.ToTensor(), tvt.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]):\n",
        "\n",
        "        self.folder_path = folder_path\n",
        "        self.label_path = label_path\n",
        "        self.files = os.listdir(self.folder_path)\n",
        "        self.files.sort()\n",
        "        self.labels = os.listdir(self.label_path)\n",
        "        self.labels.sort()\n",
        "        self.transform=transform\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "\n",
        "        image = Image.open(self.folder_path + '/' + self.files[index]).resize((512,512))\n",
        "\n",
        "        label_image = Image.open(self.label_path + '/' + self.labels[index]).resize((512,512))\n",
        "        #print(np.array(label_image))\n",
        "        #print(\"image\", image.size)\n",
        "        #print(\"label\", label_image.size)\n",
        "        #print('label_image', np.array(label_image))\n",
        "\n",
        "        tvt_form = tvt.Compose(self.transform)\n",
        "        tensor_image = tvt_form(image)\n",
        "        '''\n",
        "        label_tensor_image = toTensor(label_image)\n",
        "        label_tensor_image = label_tensor_image.long()'''\n",
        "        label_tensor_image = torch.tensor(np.array(label_image), dtype= torch.long)\n",
        "\n",
        "\n",
        "        #print(\"tensor\", tensor_image.shape)\n",
        "        #print(\"label tensor\", label_tensor_image)\n",
        "\n",
        "        return tensor_image, label_tensor_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71rCooaLMzOi"
      },
      "outputs": [],
      "source": [
        "class InitialBlock(nn.Module):\n",
        "    def __init__(self, in_channels = int, out_channels = int):\n",
        "\n",
        "        super(InitialBlock,self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.conv = nn.Conv2d(in_channels= self.in_channels,\n",
        "                              out_channels =13,\n",
        "                              kernel_size= 3,\n",
        "                              stride = 2,\n",
        "                              padding = 1,\n",
        "                              bias = False\n",
        "                              )\n",
        "        self.pooling = nn.MaxPool2d(kernel_size=2, stride = 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        #print(identity.shape)\n",
        "        x = self.conv(x)\n",
        "        #print(\"conv\", x.shape)\n",
        "        pool = self.pooling(identity)\n",
        "        #print(\"pool\", pool.shape)\n",
        "        concatenated_tensor = torch.cat((x, pool), dim = 1)\n",
        "        #print(concatenated_tensor.shape)\n",
        "        return concatenated_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf8XiPXFM5v-"
      },
      "outputs": [],
      "source": [
        "class Bottleneck_1(nn.Module):\n",
        "\n",
        "  def __init__(self, in_channels = int, out_channels = int,\n",
        "              downsample = False, dilation = int, asymmetric = int, p = 0.01):\n",
        "\n",
        "    super(Bottleneck_1,self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.dilation = dilation\n",
        "    self.asymmetric = asymmetric\n",
        "    self.pool = nn.MaxPool2d(kernel_size= 2, stride= 2)\n",
        "    self.prelu = nn.PReLU()\n",
        "\n",
        "    self.dropout = nn.Dropout2d(p = p)\n",
        "    self.downsample = downsample\n",
        "    if self.downsample is True:\n",
        "      #In the original paper I think they reduce the dimensions(channels) in 2x2\n",
        "      #Convolution too. Keeping this for now\n",
        "      self.conv2x2 = nn.Conv2d(in_channels= self.in_channels,\n",
        "                            out_channels= self.in_channels,\n",
        "                            kernel_size= 2, stride= 2, bias=False)\n",
        "      self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "      self.conv = nn.Conv2d(in_channels= self.in_channels,\n",
        "                            out_channels=int(self.out_channels/2),\n",
        "                            kernel_size=3, stride=1, padding=1, bias=False)\n",
        "      self.bn2 = nn.BatchNorm2d(int(self.out_channels/2))\n",
        "      self.conv1x1_exp = nn.Conv2d(in_channels= int(self.out_channels/2),\n",
        "                               out_channels= self.out_channels,\n",
        "                               kernel_size= 1, bias=False)\n",
        "      self.maxpool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "      self.num_channels_pad = self.out_channels - self.in_channels\n",
        "\n",
        "\n",
        "    if self.downsample is False:\n",
        "      self.conv1x1 = nn.Conv2d(in_channels= self.in_channels,\n",
        "                              out_channels= int(self.in_channels/2),\n",
        "                              kernel_size= 1, stride=1, bias=False\n",
        "                              )\n",
        "      self.bn1 = nn.BatchNorm2d(int(self.in_channels/2))\n",
        "      self.conv = nn.Conv2d(in_channels=int(self.in_channels/2),\n",
        "                            out_channels = int(self.in_channels/2),\n",
        "                            kernel_size= 3, stride=1, padding=1, bias=False)\n",
        "      self.bn2 = nn.BatchNorm2d(int(self.in_channels/2))\n",
        "      self.conv1x1_exp  =nn.Conv2d(in_channels=int(self.in_channels/2),\n",
        "                               out_channels= self.out_channels,\n",
        "                               kernel_size=1, stride=1, bias=False)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    identity = x\n",
        "    if self.downsample is True:\n",
        "      x = self.conv2x2(x)\n",
        "      x = self.bn1(x)\n",
        "      x = self.prelu(x)\n",
        "      x = self.conv(x)\n",
        "      x = self.bn2(x)\n",
        "      x = self.prelu(x)\n",
        "      x = self.conv1x1_exp(x)\n",
        "      x = self.dropout(x)\n",
        "      identity = self.maxpool(identity)\n",
        "\n",
        "      req_channels = x.shape[1] - identity.shape[1]\n",
        "      #zeros tensor needs to be changed I guess. I dont see this is a right way to do it\n",
        "      zeros = torch.zeros(identity.shape[0], req_channels,\n",
        "                          identity.shape[2], identity.shape[3]).to('cuda')\n",
        "      #identity = nn.functional.pad(identity, (0, self.num_channels_pad, 0, 0),\"constant\", 0)\n",
        "      identity = torch.cat((identity, zeros), dim = 1)\n",
        "      out = x + identity\n",
        "      #print(\"out\", out.shape)\n",
        "\n",
        "    if self.downsample is False:\n",
        "      #print(x.shape)\n",
        "      x = self.conv1x1(x)\n",
        "      x = self.bn1(x)\n",
        "      x = self.prelu(x)\n",
        "      x = self.conv(x)\n",
        "      x = self.bn2(x)\n",
        "      x = self.prelu(x)\n",
        "      x = self.conv1x1_exp(x)\n",
        "      x = self.dropout(x)\n",
        "      out = x\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DUWtd9LNM24"
      },
      "outputs": [],
      "source": [
        "'''Update: Try to generalize for other values for asymmetric convolution\n",
        "and not only 1x5,5x1'''\n",
        "\n",
        "class Bottleneck_2(nn.Module):\n",
        "\n",
        "  def __init__(self,in_channels:int, out_channels:int, dilation = 0,\n",
        "               asymmetric = False, p = 0.1):\n",
        "\n",
        "     super(Bottleneck_2,self).__init__()\n",
        "     self.in_channels = in_channels\n",
        "     self.out_channels = out_channels\n",
        "     self.dilation = dilation\n",
        "     self.asymmetric = asymmetric\n",
        "     self.prelu = nn.PReLU()\n",
        "     self.bn = nn.BatchNorm2d(int(self.out_channels/2))\n",
        "     self.dropout = nn.Dropout2d(p=p)\n",
        "\n",
        "     if asymmetric is True:\n",
        "      self.conv1x1 = nn.Conv2d(in_channels= self.in_channels,\n",
        "                              out_channels= int(self.out_channels/2),\n",
        "                              kernel_size= 1, stride=1, bias=False\n",
        "                              )\n",
        "\n",
        "      self.conv5x1 = nn.Conv2d(in_channels= int(self.out_channels/2),\n",
        "                            out_channels = int(self.out_channels/2),\n",
        "                            kernel_size= (5,1), stride=1,\n",
        "                               padding=(2,0), bias=False)\n",
        "      self.conv1x5 = nn.Conv2d(in_channels= int(self.out_channels/2),\n",
        "                            out_channels = int(self.out_channels/2),\n",
        "                            kernel_size= (1, 5), stride=1,\n",
        "                               padding=(0,2), bias=False)\n",
        "      self.conv1x1_exp  =nn.Conv2d(in_channels=int(self.in_channels/2),\n",
        "                               out_channels= self.out_channels,\n",
        "                               kernel_size=1, stride=1, bias=False)\n",
        "     if self.dilation != 0:\n",
        "      self.conv1x1 = nn.Conv2d(in_channels= self.in_channels,\n",
        "                              out_channels= int(self.out_channels/2),\n",
        "                              kernel_size= 1, stride=1, bias=False\n",
        "                              )\n",
        "      padding = ((3 - 1) * self.dilation) // 2\n",
        "      self.conv = nn.Conv2d(in_channels=int(self.out_channels/2),\n",
        "                            out_channels = int(self.out_channels/2),\n",
        "                            kernel_size= 3, stride=1, padding=padding,\n",
        "                            dilation=self.dilation, bias=False)\n",
        "\n",
        "      self.conv1x1_exp  =nn.Conv2d(in_channels=int(self.out_channels/2),\n",
        "                               out_channels= self.out_channels,\n",
        "                               kernel_size=1, stride=1, bias=False)\n",
        "  def forward(self, x):\n",
        "\n",
        "    if self.asymmetric is True:\n",
        "      #print(x.shape)\n",
        "      out = self.conv1x1(x)\n",
        "      #print(out.shape)\n",
        "      out = self.bn(out)\n",
        "      out = self.prelu(out)\n",
        "      out = self.conv5x1(out)\n",
        "      #print(out.shape)\n",
        "      out = self.bn(out)\n",
        "      out = self.prelu(out)\n",
        "      out = self.conv1x5(out)\n",
        "      #print(out.shape)\n",
        "      out = self.bn(out)\n",
        "      out = self.prelu(out)\n",
        "      out = self.conv1x1_exp(out)\n",
        "      out = self.dropout(out)\n",
        "      #print(\"asymmetric\", out.shape)\n",
        "\n",
        "    if self.dilation:\n",
        "      #print(self.dilation)\n",
        "      out = self.conv1x1(x)\n",
        "      #print(out.shape)\n",
        "      out = self.bn(out)\n",
        "      out = self.prelu(out)\n",
        "      out = self.conv(out)\n",
        "      #print(out.shape)\n",
        "      out = self.bn(out)\n",
        "      out = self.prelu(out)\n",
        "      out = self.conv1x1_exp(out)\n",
        "      out = self.dropout(out)\n",
        "      #print(\"dilation\", out.shape)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WS1T6WovDfdQ"
      },
      "outputs": [],
      "source": [
        "'''In Transpose Convolutions:\n",
        "1. Larger the Kernel Size----> Larger the output image (if no padding is added).\n",
        "2. Larger the strides, the larger the output matrix (if no padding).\n",
        "3.  the padding parameter also can be the two strings: “valid” and “same”. However,\n",
        "since we expand the input layer in transposed convolutions, if choosing “valid”,\n",
        "the output shape will be larger than the input shape. If “same” is used, then the\n",
        "output shape is forced to become the input shape multiplied by the stride. If this\n",
        "output shape is smaller than the original output shape, then only the very middle\n",
        "part of the output is maintained.\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "class Bottleneck_Upsample(nn.Module):\n",
        "  def __init__(self, in_channels = int, out_channels = int, upsample = False,\n",
        "               p = 0.1):\n",
        "    super(Bottleneck_Upsample,self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.prelu = nn.PReLU()\n",
        "    self.upsample = upsample\n",
        "    self.dropout = nn.Dropout2d(p=p)\n",
        "    self.unpool = nn.MaxUnpool2d(kernel_size= 2, stride=2)\n",
        "    self.conv_pad = nn.Conv2d(in_channels=self.in_channels,\n",
        "                              out_channels=self.out_channels,\n",
        "                              kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "    if self.upsample is True:\n",
        "\n",
        "\n",
        "\n",
        "      self.trans_conv1x1 = nn.ConvTranspose2d(in_channels=self.in_channels,\n",
        "                                          out_channels= self.in_channels,\n",
        "                                          kernel_size=1, stride=1, bias=False)\n",
        "      self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "      self.tran_conv = nn.ConvTranspose2d(in_channels=self.in_channels,\n",
        "                                          out_channels= self.out_channels,\n",
        "                                          kernel_size=3, stride=2, padding=1,\n",
        "                                          output_padding=1, bias= False)\n",
        "      self.bn2 = nn.BatchNorm2d(self.out_channels)\n",
        "\n",
        "      self.trans_conv1x1exp = nn.ConvTranspose2d(in_channels=self.out_channels,\n",
        "                                          out_channels= self.out_channels,\n",
        "                                          kernel_size=1, stride=1, bias=False)\n",
        "      self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1, return_indices=True)\n",
        "\n",
        "\n",
        "    elif self.upsample is False:\n",
        "\n",
        "      self.trans_conv1x1 = nn.ConvTranspose2d(in_channels=self.in_channels,\n",
        "                                          out_channels= self.in_channels,\n",
        "                                          kernel_size=1, stride=1, bias=False)\n",
        "      self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "      self.tran_conv = nn.ConvTranspose2d(in_channels= self.in_channels,\n",
        "                                          out_channels= self.out_channels,\n",
        "                                          kernel_size=3, stride=1, padding=1,\n",
        "                                          output_padding=0, bias=False)\n",
        "      self.bn2 = nn.BatchNorm2d(self.out_channels)\n",
        "      self.trans_conv1x1exp = nn.ConvTranspose2d(in_channels=self.out_channels,\n",
        "                                          out_channels= self.out_channels,\n",
        "                                          kernel_size=1, stride=1, bias=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = None\n",
        "    x_copy = x\n",
        "    if self.upsample is True:\n",
        "      #print(\"upsampling\")\n",
        "      #print(\"x\", x.shape)\n",
        "      out = self.trans_conv1x1(x)\n",
        "      out = self.bn1(out)\n",
        "      out = self.prelu(out)\n",
        "      out = self.tran_conv(out)\n",
        "      out = self.bn2(out)\n",
        "      out = self.prelu(out)\n",
        "      out = self.trans_conv1x1exp(out)\n",
        "      out = self.dropout(out)\n",
        "      #print(\"out\",out.shape)\n",
        "      output, indices = self.maxpool(x_copy)\n",
        "      identity = self.unpool(x_copy, indices)\n",
        "      identity = self.conv_pad(identity)\n",
        "      #print(\"identity after unpool and conv pad\", identity.shape)\n",
        "      out = identity + out\n",
        "      #print(\"out after concat\", out.shape)\n",
        "\n",
        "    elif self.upsample is False:\n",
        "      #print(\"Not Upsampling\")\n",
        "      out = self.trans_conv1x1(x)\n",
        "      out = self.bn1(out)\n",
        "      out = self.prelu(out)\n",
        "      out = self.tran_conv(out)\n",
        "      out = self.bn2(out)\n",
        "      out = self.prelu(out)\n",
        "      out = self.trans_conv1x1exp(out)\n",
        "      out = self.dropout(out)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #print(out.shape)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTgMX0zcjzGa"
      },
      "outputs": [],
      "source": [
        "class ENet(nn.Module):\n",
        "  def __init__(self, num_classes = int):\n",
        "\n",
        "    super(ENet, self).__init__()\n",
        "    if num_classes is None:\n",
        "      self.num_classes = 3\n",
        "    else:\n",
        "      self.num_classes = num_classes\n",
        "\n",
        "    #Initial block\n",
        "\n",
        "    self.initial = InitialBlock(in_channels= 3, out_channels= 16)\n",
        "    #Encoder\n",
        "    self.Encoder = nn.Sequential(Bottleneck_1(in_channels= 16, out_channels= 64, downsample= True),\n",
        "    Bottleneck_1(in_channels= 64, out_channels= 64, downsample= False),\n",
        "    Bottleneck_1(in_channels= 64, out_channels= 64),\n",
        "    Bottleneck_1(in_channels= 64, out_channels= 64),\n",
        "    Bottleneck_1(in_channels= 64, out_channels= 64),\n",
        "    Bottleneck_1(in_channels= 64, out_channels= 128, downsample= True,),\n",
        "    Bottleneck_1(in_channels= 128, out_channels= 128, downsample= False),\n",
        "    Bottleneck_2(in_channels= 128, out_channels= 128, dilation= 2),\n",
        "    Bottleneck_2(in_channels= 128, out_channels= 128, asymmetric= True),\n",
        "    Bottleneck_2(in_channels= 128, out_channels= 128, dilation= 4),\n",
        "    Bottleneck_1(in_channels= 128, out_channels= 128),\n",
        "    Bottleneck_2(in_channels= 128, out_channels= 128, dilation=8),\n",
        "    Bottleneck_2(in_channels= 128, out_channels= 128, asymmetric= True),\n",
        "    Bottleneck_2(in_channels= 128, out_channels= 128, dilation=16),\n",
        "    Bottleneck_1(in_channels= 128, out_channels= 128, downsample= False),\n",
        "    Bottleneck_2(in_channels= 128, out_channels= 128, dilation= 2),\n",
        "    Bottleneck_2(in_channels= 128, out_channels= 128, asymmetric= True),\n",
        "    Bottleneck_2(in_channels= 128, out_channels= 128, dilation= 4),\n",
        "    Bottleneck_1(in_channels= 128, out_channels= 128),\n",
        "    Bottleneck_2(in_channels= 128, out_channels= 128, dilation=8),\n",
        "    Bottleneck_2(in_channels= 128, out_channels= 128, asymmetric= True),\n",
        "    Bottleneck_2(in_channels= 128, out_channels= 128, dilation=16)\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "    #Decoder\n",
        "    self.Decoder = nn.Sequential(\n",
        "    Bottleneck_Upsample(in_channels= 128, out_channels= 64, upsample= True),\n",
        "    Bottleneck_Upsample(in_channels= 64, out_channels= 64, upsample= False),\n",
        "    Bottleneck_Upsample(in_channels= 64, out_channels= 64),\n",
        "    Bottleneck_Upsample(in_channels= 64, out_channels= 16, upsample= True),\n",
        "    Bottleneck_Upsample(in_channels= 16, out_channels= 16),\n",
        "    nn.ConvTranspose2d(in_channels= 16, out_channels= self.num_classes,\n",
        "                                   kernel_size= 3, stride= 2,\n",
        "                                  padding= 1, output_padding=1, bias= False))\n",
        "  def forward(self, x):\n",
        "    out = self.initial(x)\n",
        "    out = self.Encoder(out)\n",
        "    out = self.Decoder(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diheJ-QC5-zY"
      },
      "outputs": [],
      "source": [
        "def get_class_weights(dataset, num_classes, c=1.02):\n",
        "    '''\n",
        "    Calculate class weights for each class based on the entire dataset\n",
        "\n",
        "    Arguments:\n",
        "    - dataset : The dataset object containing all labels\n",
        "    - num_classes : The number of classes\n",
        "\n",
        "    Returns:\n",
        "    - class_weights : An array of class weights\n",
        "    '''\n",
        "\n",
        "    # Assuming 'labels' is a list or tensor of all labels in the dataset\n",
        "    labels = torch.cat([dataset[i][1] for i in range(len(dataset))])\n",
        "    labels = labels.flatten()\n",
        "    counts = torch.bincount(labels, minlength=num_classes)\n",
        "\n",
        "    # Calculate propensity scores and class weights\n",
        "    all_labels_count = counts.sum().item()\n",
        "    propensity_score = counts.float() / all_labels_count\n",
        "    class_weights = 1 / (torch.log(c + propensity_score))\n",
        "\n",
        "    return class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAaMlUjKsI4y"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Training loop\n",
        "'''\n",
        "In the mapillary dataset, the labels are already encoded in the numbering scheme required by nn.CrossEntropyLoss\n",
        "We do not have to do anything except pass the labels to the loss function\n",
        "\n",
        "'''\n",
        "def training(model, dataloader, lr = 5e-4, weight_decay = 2e-4, epochs = 7):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  net = model.to(device)\n",
        "  optimizer = torch.optim.Adam(params= model.parameters(), lr= lr, weight_decay= weight_decay)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  total_loss = []\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = []\n",
        "    for batch_idx, (inputs, target) in enumerate(dataloader):\n",
        "      #print(inputs.shape)\n",
        "      inputs = inputs.to(device)\n",
        "      target = target.to(device)\n",
        "      #print(target.shape)\n",
        "      \"\"\"In PyTorch, the torch.nn.CrossEntropyLoss expects the target tensor\n",
        "      to be a 3D tensor of shape [N, H, W], where N is the batch size, and H and W\n",
        "       are the height and width of the target.\"\"\"\n",
        "      target = torch.squeeze(target, dim=1)\n",
        "      optimizer.zero_grad()\n",
        "      output = model(inputs)\n",
        "      output = torch.squeeze(output, dim=1)\n",
        "      loss = criterion(output, target)\n",
        "      running_loss.append(loss.item())\n",
        "      #print(loss.item())\n",
        "      if batch_idx % 100 == 0:\n",
        "        print('[%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, sum(running_loss)/len(running_loss)))\n",
        "        total_loss.append(sum(running_loss)/len(running_loss))\n",
        "        running_loss = []\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    print(\"Finished Training\")\n",
        "  fig = plt.figure(figsize=(10, 8))\n",
        "  plt.plot(total_loss, label='Training Losses')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  torch.save(model.state_dict(), \"/content/drive/MyDrive/model.pth\")\n",
        "  return total_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxLVeQ9sjhe0"
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset(folder_path= \"/content/drive/MyDrive/mapillary_unzipped/training/images\",\n",
        "                        label_path= \"/content/drive/MyDrive/mapillary_unzipped/training/v1.2/labels\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9k66s6FyJf9",
        "outputId": "62182857-5290-44a5-cd00-4b5702c64327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DbKHdgux5Wf"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataloader = DataLoader(dataset, batch_size= 10, num_workers= 0, shuffle= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3odDQqAtw44"
      },
      "outputs": [],
      "source": [
        "def get_class_weights(dataloader, num_classes, c=1.02):\n",
        "    '''\n",
        "    Compute class weights using PyTorch operations.\n",
        "\n",
        "    Arguments:\n",
        "    - dataloader : DataLoader object that iterates over the dataset.\n",
        "    - num_classes : The number of classes.\n",
        "\n",
        "    Return:\n",
        "    - class_weights : Tensor with the class weights for each class.\n",
        "    '''\n",
        "    all_labels = []\n",
        "    for batch_index, (_, labels) in enumerate(dataloader):\n",
        "        all_labels.append(labels.flatten())\n",
        "        if batch_index % 100 == 0:\n",
        "          print(f\"images done: {batch_index*10}\")\n",
        "        if batch_index*10 == 5000:\n",
        "          break\n",
        "\n",
        "    all_labels = torch.cat(all_labels)\n",
        "    each_class = torch.bincount(all_labels, minlength=num_classes)\n",
        "    total_samples = all_labels.sum().item()\n",
        "    prospensity_score = each_class.float() / total_samples\n",
        "    class_weights = 1.0 / (torch.log(torch.tensor(c)) + prospensity_score)\n",
        "    torch.save(class_weights, '/content/drive/MyDrive/Colab Notebooks/class_weights.pt')\n",
        "    print(\"weights saved\")\n",
        "\n",
        "    return class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0Ebyv9xukty",
        "outputId": "b15e07c1-2420-40d1-c8cb-379a54e7ef9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images done: 0\n",
            "images done: 1000\n",
            "images done: 2000\n",
            "images done: 3000\n",
            "images done: 4000\n",
            "images done: 5000\n",
            "weights saved\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([50.4982, 50.4955, 49.6714, 49.2335, 50.2077, 50.0399, 49.7079, 50.1292,\n",
              "        50.2232, 50.4138, 50.2433, 50.1609, 50.3607, 36.5860, 50.2879, 47.5590,\n",
              "        49.7199, 40.4405, 50.4043, 50.1580, 50.4600, 50.4748, 50.4969, 49.7671,\n",
              "        49.1286, 50.2835, 50.4896, 31.7954, 50.1468, 49.4514, 38.8237, 50.4525,\n",
              "        50.4343, 50.4870, 50.4884, 49.8701, 50.4668, 50.4960, 50.4920, 50.4589,\n",
              "        50.4945, 50.4378, 50.4930, 50.4939, 50.4392, 49.6626, 50.4051, 50.0745,\n",
              "        50.3024, 50.4183, 50.0313, 50.4266, 50.4306, 50.4903, 50.2489, 47.2169,\n",
              "        50.4953, 50.4313, 50.4589, 50.4443, 50.4919, 50.1403, 50.4926, 50.3881,\n",
              "        48.5587, 48.7835])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "get_class_weights(dataloader, 66)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6DIi_-Yx_D_"
      },
      "outputs": [],
      "source": [
        "model = ENet(num_classes= 66)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "NNXKftvpc_Ll",
        "outputId": "1e4a0147-01f0-40db-b2ce-4ab1fe1c2131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,     1] loss: 4.189\n",
            "[1,   101] loss: 3.441\n",
            "[1,   201] loss: 2.140\n",
            "[1,   301] loss: 1.788\n",
            "[1,   401] loss: 1.625\n",
            "[1,   501] loss: 1.536\n",
            "[1,   601] loss: 1.464\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ef8c65c61b8f>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-b87a83216c9f>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, dataloader, lr, weight_decay, epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0;31m#print(inputs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Note: Dilation parameter has an influence on image size\n",
        "\n",
        "\"\"\"\n",
        "training(model, dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzxMP89QToXW"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/enet.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R89N32kiT9gf"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "model = ENet(num_classes=66)  # Replace ENet with the actual class or import statement\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/enet.pth'))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Define the preprocessing transformations\n",
        "transform = tvt.Compose([\n",
        "    tvt.Resize((512, 512)),  # Replace with your input dimensions\n",
        "    tvt.ToTensor(),\n",
        "    # Add any other transformations you used during training (e.g., normalization)\n",
        "])\n",
        "\n",
        "# Load and preprocess the image\n",
        "img = Image.open(\"/content/drive/MyDrive/mapillary_unzipped/testing/images/___QXeb8e952hTD6EaQVEQ.jpg\")  # Load the image\n",
        "img = transform(img)  # Apply the transformations\n",
        "img = img.unsqueeze(0)  # Add a batch dimension\n",
        "img = img.to(\"cuda\")\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    output = model(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvO8uqkfVAJJ",
        "outputId": "35782cc1-fd1d-4e4e-cb57-bd1029fedd2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[27, 27, 27,  ..., 27, 27, 27],\n",
              "        [27, 27, 27,  ..., 27, 27, 27],\n",
              "        [27, 27, 27,  ..., 27, 27, 27],\n",
              "        ...,\n",
              "        [13, 13, 13,  ..., 13, 13, 13],\n",
              "        [13, 13, 13,  ..., 13, 13, 13],\n",
              "        [13, 13, 13,  ..., 13, 13, 13]], device='cuda:0')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_classes = torch.argmax(output, dim=1)\n",
        "predicted_classes = predicted_classes.squeeze(0)\n",
        "predicted_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "OaNZtMoLVYTE",
        "outputId": "e38f9cbd-dfa7-4d79-f560-31b9f8fe8345"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAAAAADRE4smAAAFK0lEQVR4nO3WMWrDQBBA0VFUR5DakPvfLrC9IY0hbuxURob/HkyjYllGv9jtMpR9nH0BziWAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AbyN9WReZN9nu7zueP71wp97c6y/uf88s46Zme17Zq4z+3X/mWPWHE+PW8fMenRo3v1ejjW3fd7N2+3sa7bPs+/AqbwB4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOIEECeAOAHECSBOAHECiBNAnADiBBAngDgBxAkgTgBxAogTQJwA4gQQJ4A4AcQJIE4AcQKIE0CcAOJ+AaxvIwLgD8d2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=512x512>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "segmentation = predicted_classes.cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "3C9vFJMzzG9D",
        "outputId": "fc2de57e-160f-40aa-82df-61c8ccc6d432"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3079\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 512), '|u1')",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-e48d7cddd045>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3081\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Cannot handle this data type: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtypekey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3083\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3084\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m         \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 512), |u1"
          ]
        }
      ],
      "source": [
        "Image.fromarray(segmentation.astype(np.uint8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJzsz-PIjz3s"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/drive/MyDrive/mapillary_unzipped/config_v1.2.json\", \"r\") as f:\n",
        "  config = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt-rxCrK0ANw",
        "outputId": "cd823213-9e1d-44e5-a8d1-bf7a55e468c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'color': [0, 192, 0],\n",
              " 'instances': True,\n",
              " 'readable': 'Ground Animal',\n",
              " 'name': 'animal--ground-animal',\n",
              " 'evaluate': True}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config[\"labels\"][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "tQxTu7h5XTtR",
        "outputId": "6ad33a72-16a7-4ebc-f9b8-3992798f9714"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rgb_image = np.zeros((512, 512, 3), dtype=np.uint8)\n",
        "for index, info in enumerate(config['labels']):\n",
        "    rgb_image[segmentation == index] = info['color']\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(rgb_image)\n",
        "plt.axis('off')  # Turn off axis numbers\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIWan94nB--c"
      },
      "outputs": [],
      "source": [
        "array = np.array(Image.open(\"/content/drive/MyDrive/sample images/labels/DaEwgFJdh-5zMGQTlRBqCg.png\").resize((512,512)))\n",
        "array[1000:][1000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDPcutVYNvRP"
      },
      "outputs": [],
      "source": [
        "np.array(Image.open(\"/content/drive/MyDrive/sample images/labels/DaEwgFJdh-5zMGQTlRBqCg.png\").resize((512,512)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDJgk3EeODTl"
      },
      "outputs": [],
      "source": [
        "config[\"labels\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sv8yHd3UYjk"
      },
      "outputs": [],
      "source": [
        "img = Image.open(\"/content/drive/MyDrive/sample images/labels/DaEwgFJdh-5zMGQTlRBqCg.png\").resize((512,512))\n",
        "tensor = tvt.transforms.ToTensor()(img)\n",
        "torch.min(tensor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbiVS-ZRVvh6"
      },
      "outputs": [],
      "source": [
        "zeros = torch.zeros(48, 128, 128)\n",
        "zeros.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDjZ4fEVKLn_"
      },
      "outputs": [],
      "source": [
        "64-16\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J03jLF35KMtI"
      },
      "outputs": [],
      "source": [
        "2//2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXng2zgr0dAh"
      },
      "outputs": [],
      "source": [
        "loader2 = DataLoader(dataset, batch_size= 100, num_workers= 2, shuffle= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "8mhhDFrg7BbS",
        "outputId": "900299ec-40a0-49d1-df2c-a1c155ae8f8b"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-8a3834cb1763>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i in loader2:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yf0yG1v57H5-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}